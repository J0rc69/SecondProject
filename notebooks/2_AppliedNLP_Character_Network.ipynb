{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a577e72-7f0c-470c-b713-3da771c9befb",
   "metadata": {},
   "source": [
    "1 – Imports + load the correct files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756dec2a-3790-4686-9e3d-1789d1745687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using files:\n",
      "War and Peace  -> War-and-Peace.txt\n",
      "Anna Karenina  -> Anna-Karenina.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200000, 200000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --------- Load the text files from ../data ---------\n",
    "DATA_DIR = Path(\"../data\")\n",
    "\n",
    "def find_file_by_keywords(dir_path, keywords):\n",
    "    \"\"\"\n",
    "    Find the first file in dir_path whose name contains ALL keywords.\n",
    "    Works with names like 'War-and-Peace.txt' or long Gutenberg names.\n",
    "    \"\"\"\n",
    "    for path in dir_path.iterdir():\n",
    "        if path.is_file():\n",
    "            name_lower = path.name.lower()\n",
    "            if all(k.lower() in name_lower for k in keywords):\n",
    "                return path\n",
    "    raise FileNotFoundError(f\"No file found in {dir_path} with keywords {keywords}\")\n",
    "\n",
    "war_and_peace_path = find_file_by_keywords(DATA_DIR, [\"war\", \"peace\"])\n",
    "anna_karenina_path = find_file_by_keywords(DATA_DIR, [\"anna\", \"karenina\"])\n",
    "\n",
    "print(\"Using files:\")\n",
    "print(\"War and Peace  ->\", war_and_peace_path.name)\n",
    "print(\"Anna Karenina  ->\", anna_karenina_path.name)\n",
    "\n",
    "with war_and_peace_path.open(encoding=\"utf-8\") as f:\n",
    "    war_and_peace_text = f.read()\n",
    "\n",
    "with anna_karenina_path.open(encoding=\"utf-8\") as f:\n",
    "    anna_karenina_text = f.read()\n",
    "\n",
    "# Use only first N characters to keep things fast\n",
    "N = 200_000   # you can increase later if you want\n",
    "war_and_peace_text_sample = war_and_peace_text[:N]\n",
    "anna_karenina_text_sample = anna_karenina_text[:N]\n",
    "\n",
    "len(war_and_peace_text_sample), len(anna_karenina_text_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bdabe-46ba-4360-9e9b-277a309f91d0",
   "metadata": {},
   "source": [
    "2 – spaCy setup + sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacec980-c0f7-4ac6-acfb-62757bdbe164",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7242f38-248c-48c6-a92a-f704dd14478e",
   "metadata": {},
   "source": [
    "3 – Name normalization + extract_character_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be6a6b7-1d86-4f1a-beca-fa2fa8f69c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 78)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------- Map name variants to canonical names ---------\n",
    "NAME_NORMALIZATION = {\n",
    "    # --- War and Peace ---\n",
    "    \"Pierre\": \"Pierre Bezukhov\",\n",
    "    \"Bezukhov\": \"Pierre Bezukhov\",\n",
    "\n",
    "    \"Prince Andrei\": \"Andrei Bolkonsky\",\n",
    "    \"Andrew\": \"Andrei Bolkonsky\",\n",
    "    \"Prince Andrew\": \"Andrei Bolkonsky\",\n",
    "    \"Andrei\": \"Andrei Bolkonsky\",\n",
    "    \"Bolkonsky\": \"Andrei Bolkonsky\",\n",
    "\n",
    "    \"Natasha\": \"Natasha Rostova\",\n",
    "    \"Natalie\": \"Natasha Rostova\",\n",
    "    \"Rostova\": \"Natasha Rostova\",\n",
    "\n",
    "    # --- Anna Karenina ---\n",
    "    \"Anna\": \"Anna Karenina\",\n",
    "    \"Karenina\": \"Anna Karenina\",\n",
    "\n",
    "    \"Vronsky\": \"Alexei Vronsky\",\n",
    "\n",
    "    \"Levin\": \"Konstantin Levin\",\n",
    "    \"Konstantin\": \"Konstantin Levin\",\n",
    "\n",
    "    \"Kitty\": \"Ekaterina Shcherbatskaya\",\n",
    "    \"Ekaterina Shcherbatskaya\": \"Ekaterina Shcherbatskaya\",\n",
    "\n",
    "    \"Oblonsky\": \"Stepan Arkadyevitch Oblonsky\",\n",
    "    \"Stepan Arkadyitch\": \"Stepan Arkadyevitch Oblonsky\",\n",
    "    \"Stepan Arkadyevitch\": \"Stepan Arkadyevitch Oblonsky\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    return NAME_NORMALIZATION.get(name, name)\n",
    "\n",
    "# --------- Extract character mentions per sentence ---------\n",
    "def extract_character_mentions(text, book_label):\n",
    "    doc = nlp(text)\n",
    "    results = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        persons = [ent.text for ent in sent.ents if ent.label_ == \"PERSON\"]\n",
    "        if not persons:\n",
    "            continue\n",
    "\n",
    "        normalized = sorted(set(normalize_name(p) for p in persons))\n",
    "        if len(normalized) < 2:\n",
    "            continue\n",
    "\n",
    "        results.append({\n",
    "            \"book\": book_label,\n",
    "            \"sentence\": sent.text.strip(),\n",
    "            \"characters\": normalized,\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "war_sent_data = extract_character_mentions(war_and_peace_text_sample, \"War and Peace\")\n",
    "anna_sent_data = extract_character_mentions(anna_karenina_text_sample, \"Anna Karenina\")\n",
    "\n",
    "len(war_sent_data), len(anna_sent_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407623e1-182d-404c-933d-03c1ebd7ee36",
   "metadata": {},
   "source": [
    "4 – Build co-occurrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db40d4bf-1c72-4dd9-b277-f17e6dd252b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_cooccurrence_edges(sent_data):\n",
    "    edges = Counter()\n",
    "    for item in sent_data:\n",
    "        chars = item[\"characters\"]\n",
    "        for c1, c2 in itertools.combinations(chars, 2):\n",
    "            pair = tuple(sorted((c1, c2)))\n",
    "            edges[pair] += 1\n",
    "    return edges\n",
    "\n",
    "war_edges = build_cooccurrence_edges(war_sent_data)\n",
    "anna_edges = build_cooccurrence_edges(anna_sent_data)\n",
    "\n",
    "len(war_edges), len(anna_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bff031-2096-4e5c-9094-dcfc945bd2cd",
   "metadata": {},
   "source": [
    "5 – Create graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e4a052-da5f-4b99-aa93-902033f3fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8, 5, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def edges_to_graph(edge_weights, min_weight=3):\n",
    "    G = nx.Graph()\n",
    "    for (c1, c2), w in edge_weights.items():\n",
    "        if w >= min_weight:\n",
    "            G.add_edge(c1, c2, weight=w)\n",
    "    return G\n",
    "\n",
    "G_war = edges_to_graph(war_edges, min_weight=3)\n",
    "G_anna = edges_to_graph(anna_edges, min_weight=3)\n",
    "\n",
    "G_war.number_of_nodes(), G_war.number_of_edges(), G_anna.number_of_nodes(), G_anna.number_of_edges()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
