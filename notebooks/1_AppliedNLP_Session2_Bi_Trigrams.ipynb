{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfe6146",
   "metadata": {},
   "source": [
    "# 1_AppliedNLP_Session2_Bi_Trigrams\n",
    "\n",
    "This notebook analyzes the most frequent **bigrams** and **trigrams** in *War and Peace* and *Anna Karenina* by Leo Tolstoy. The structure follows the same logic as `01_frequent_words(1).ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc9d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Ensure tokenizer resources are available (handles newer NLTK too)\n",
    "def _ensure_nltk():\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt\")\n",
    "    except LookupError:\n",
    "        nltk.download(\"punkt\", quiet=True)\n",
    "    # Some NLTK versions require 'punkt_tab' separately\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/punkt_tab\")\n",
    "    except LookupError:\n",
    "        try:\n",
    "            nltk.download(\"punkt_tab\", quiet=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "_ensure_nltk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f44b92",
   "metadata": {},
   "source": [
    "### üîç What does `Counter` do?\n",
    "`Counter` from Python's `collections` module counts how many times each item appears in a list. For example:\n",
    "```python\n",
    "Counter(['apple', 'banana', 'apple'])\n",
    "```\n",
    "returns:\n",
    "```\n",
    "Counter({'apple': 2, 'banana': 1})\n",
    "```\n",
    "This helps us find how frequently each bigram or trigram occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e259cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 572173 tokens from War and Peace\n",
      "Loaded 359574 tokens from Anna Karenina\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Construct the path to the data folder (one level up from notebooks/)\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), \"data\")\n",
    "\n",
    "file_war = os.path.join(data_dir, \"The Project Gutenberg eBook of War and Peace, by Leo Tolstoy.txt\")\n",
    "file_anna = os.path.join(data_dir, \"The Project Gutenberg eBook of Anna Karenina, by Leo Tolstoy.txt\")\n",
    "\n",
    "\n",
    "def load_and_clean_text(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = text.lower()\n",
    "    for p in string.punctuation:\n",
    "        text = text.replace(p, ' ')\n",
    "    # Tokenize with NLTK; if resources are missing, fall back to regex\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "    except LookupError:\n",
    "        # Fallback: simple regex tokenizer to avoid NLTK data errors\n",
    "        tokens = re.findall(r\"[a-zA-Z]+\", text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # keep only alphabetic tokens\n",
    "    return tokens\n",
    "\n",
    "tokens_war = load_and_clean_text(file_war)\n",
    "tokens_anna = load_and_clean_text(file_anna)\n",
    "\n",
    "print(f\"Loaded {len(tokens_war)} tokens from War and Peace\")\n",
    "print(f\"Loaded {len(tokens_anna)} tokens from Anna Karenina\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c048bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate bigrams and trigrams\n",
    "bigrams_war = list(ngrams(tokens_war, 2))\n",
    "bigrams_anna = list(ngrams(tokens_anna, 2))\n",
    "trigrams_war = list(ngrams(tokens_war, 3))\n",
    "trigrams_anna = list(ngrams(tokens_anna, 3))\n",
    "\n",
    "# Count frequencies\n",
    "counter_bi_war = Counter(bigrams_war)\n",
    "counter_bi_anna = Counter(bigrams_anna)\n",
    "counter_tri_war = Counter(trigrams_war)\n",
    "counter_tri_anna = Counter(trigrams_anna)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d023f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Bigrams - War and Peace\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the</td>\n",
       "      <td>4072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in the</td>\n",
       "      <td>2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to the</td>\n",
       "      <td>2329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and the</td>\n",
       "      <td>1482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>at the</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>on the</td>\n",
       "      <td>1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>he had</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prince andrew</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>did not</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>he was</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>with a</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it was</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>from the</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with the</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>of his</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>by the</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to be</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>had been</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>in a</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>to him</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           N-gram  Frequency\n",
       "1          of the       4072\n",
       "2          in the       2336\n",
       "3          to the       2329\n",
       "4         and the       1482\n",
       "5          at the       1346\n",
       "6          on the       1334\n",
       "7          he had       1210\n",
       "8   prince andrew       1065\n",
       "9         did not       1048\n",
       "10         he was        951\n",
       "11         with a        948\n",
       "12         it was        881\n",
       "13       from the        877\n",
       "14       with the        804\n",
       "15         of his        802\n",
       "16         by the        777\n",
       "17          to be        776\n",
       "18       had been        756\n",
       "19           in a        745\n",
       "20         to him        733"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Bigrams - Anna Karenina\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in the</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to the</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>he had</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he was</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>at the</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and the</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it was</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on the</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>did not</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of his</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>that he</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>it s</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>he said</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>to be</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>alexey alexandrovitch</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to her</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>had been</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>don t</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>stepan arkadyevitch</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   N-gram  Frequency\n",
       "1                  of the       1945\n",
       "2                  in the       1634\n",
       "3                  to the       1007\n",
       "4                  he had       1004\n",
       "5                  he was        886\n",
       "6                  at the        886\n",
       "7                 and the        729\n",
       "8                  it was        673\n",
       "9                  on the        655\n",
       "10                did not        643\n",
       "11                 of his        624\n",
       "12                that he        611\n",
       "13                   it s        606\n",
       "14                he said        600\n",
       "15                  to be        599\n",
       "16  alexey alexandrovitch        571\n",
       "17                 to her        567\n",
       "18               had been        550\n",
       "19                  don t        550\n",
       "20    stepan arkadyevitch        547"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Trigrams - War and Peace\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he did not</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i don t</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one of the</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>out of the</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>that he was</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commander in chief</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>as soon as</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>up to the</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he could not</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>that it was</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the drawing room</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the old prince</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>which he had</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>did not know</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in front of</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a long time</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of the french</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the commander in</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>he had been</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>to him and</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                N-gram  Frequency\n",
       "1           he did not        223\n",
       "2              i don t        203\n",
       "3           one of the        187\n",
       "4           out of the        178\n",
       "5          that he was        155\n",
       "6   commander in chief        147\n",
       "7           as soon as        146\n",
       "8            up to the        129\n",
       "9         he could not        129\n",
       "10         that it was        125\n",
       "11    the drawing room        115\n",
       "12      the old prince        115\n",
       "13        which he had        114\n",
       "14        did not know        113\n",
       "15         in front of        113\n",
       "16         a long time        111\n",
       "17       of the french        105\n",
       "18    the commander in        103\n",
       "19         he had been        102\n",
       "20          to him and        102"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Trigrams - Anna Karenina\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i don t</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he could not</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>he did not</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>out of the</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i can t</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that he had</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>said stepan arkadyevitch</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that he was</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>in spite of</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>that it was</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>he had been</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>she could not</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>he said to</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>don t know</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>she did not</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>that she was</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>it s not</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>at the same</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i m not</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>it s a</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      N-gram  Frequency\n",
       "1                    i don t        254\n",
       "2               he could not        198\n",
       "3                 he did not        197\n",
       "4                 out of the        177\n",
       "5                    i can t        142\n",
       "6                that he had        136\n",
       "7   said stepan arkadyevitch        125\n",
       "8                that he was        121\n",
       "9                in spite of        116\n",
       "10               that it was        107\n",
       "11               he had been        103\n",
       "12             she could not        101\n",
       "13                he said to         96\n",
       "14                don t know         96\n",
       "15               she did not         95\n",
       "16              that she was         87\n",
       "17                  it s not         84\n",
       "18               at the same         83\n",
       "19                   i m not         82\n",
       "20                    it s a         82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Convert to DataFrame for easy display\n",
    "def top_ngrams(counter, n=20):\n",
    "    df = pd.DataFrame(counter.most_common(n), columns=['N-gram', 'Frequency'])\n",
    "    df['N-gram'] = df['N-gram'].apply(lambda x: ' '.join(x))\n",
    "    df.index = df.index + 1  # Shift index to start at 1\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"Top 20 Bigrams - War and Peace\")\n",
    "display(top_ngrams(counter_bi_war))\n",
    "\n",
    "print(\"Top 20 Bigrams - Anna Karenina\")\n",
    "display(top_ngrams(counter_bi_anna))\n",
    "\n",
    "print(\"Top 20 Trigrams - War and Peace\")\n",
    "display(top_ngrams(counter_tri_war))\n",
    "\n",
    "print(\"Top 20 Trigrams - Anna Karenina\")\n",
    "display(top_ngrams(counter_tri_anna))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e174825d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Merged Comparison (Bigrams)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>War and Peace Count</th>\n",
       "      <th>Anna Karenina Count</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118292</th>\n",
       "      <td>of the</td>\n",
       "      <td>4072</td>\n",
       "      <td>1945</td>\n",
       "      <td>6017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184003</th>\n",
       "      <td>in the</td>\n",
       "      <td>2336</td>\n",
       "      <td>1634</td>\n",
       "      <td>3970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279164</th>\n",
       "      <td>to the</td>\n",
       "      <td>2329</td>\n",
       "      <td>1007</td>\n",
       "      <td>3336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119716</th>\n",
       "      <td>at the</td>\n",
       "      <td>1346</td>\n",
       "      <td>886</td>\n",
       "      <td>2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81181</th>\n",
       "      <td>he had</td>\n",
       "      <td>1210</td>\n",
       "      <td>1004</td>\n",
       "      <td>2214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228332</th>\n",
       "      <td>and the</td>\n",
       "      <td>1482</td>\n",
       "      <td>729</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177063</th>\n",
       "      <td>on the</td>\n",
       "      <td>1334</td>\n",
       "      <td>655</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125479</th>\n",
       "      <td>he was</td>\n",
       "      <td>951</td>\n",
       "      <td>886</td>\n",
       "      <td>1837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114483</th>\n",
       "      <td>did not</td>\n",
       "      <td>1048</td>\n",
       "      <td>643</td>\n",
       "      <td>1691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257884</th>\n",
       "      <td>it was</td>\n",
       "      <td>881</td>\n",
       "      <td>673</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108292</th>\n",
       "      <td>with a</td>\n",
       "      <td>948</td>\n",
       "      <td>533</td>\n",
       "      <td>1481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180660</th>\n",
       "      <td>of his</td>\n",
       "      <td>802</td>\n",
       "      <td>624</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262104</th>\n",
       "      <td>to be</td>\n",
       "      <td>776</td>\n",
       "      <td>599</td>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276651</th>\n",
       "      <td>had been</td>\n",
       "      <td>756</td>\n",
       "      <td>550</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19041</th>\n",
       "      <td>with the</td>\n",
       "      <td>804</td>\n",
       "      <td>480</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142604</th>\n",
       "      <td>that he</td>\n",
       "      <td>669</td>\n",
       "      <td>611</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140222</th>\n",
       "      <td>from the</td>\n",
       "      <td>877</td>\n",
       "      <td>381</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91757</th>\n",
       "      <td>to him</td>\n",
       "      <td>733</td>\n",
       "      <td>520</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273436</th>\n",
       "      <td>in a</td>\n",
       "      <td>745</td>\n",
       "      <td>389</td>\n",
       "      <td>1134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39571</th>\n",
       "      <td>for the</td>\n",
       "      <td>633</td>\n",
       "      <td>453</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          N-gram  War and Peace Count  Anna Karenina Count  Total\n",
       "118292    of the                 4072                 1945   6017\n",
       "184003    in the                 2336                 1634   3970\n",
       "279164    to the                 2329                 1007   3336\n",
       "119716    at the                 1346                  886   2232\n",
       "81181     he had                 1210                 1004   2214\n",
       "228332   and the                 1482                  729   2211\n",
       "177063    on the                 1334                  655   1989\n",
       "125479    he was                  951                  886   1837\n",
       "114483   did not                 1048                  643   1691\n",
       "257884    it was                  881                  673   1554\n",
       "108292    with a                  948                  533   1481\n",
       "180660    of his                  802                  624   1426\n",
       "262104     to be                  776                  599   1375\n",
       "276651  had been                  756                  550   1306\n",
       "19041   with the                  804                  480   1284\n",
       "142604   that he                  669                  611   1280\n",
       "140222  from the                  877                  381   1258\n",
       "91757     to him                  733                  520   1253\n",
       "273436      in a                  745                  389   1134\n",
       "39571    for the                  633                  453   1086"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Merged Comparison (Trigrams)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N-gram</th>\n",
       "      <th>War and Peace Count</th>\n",
       "      <th>Anna Karenina Count</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165572</th>\n",
       "      <td>i don t</td>\n",
       "      <td>203</td>\n",
       "      <td>254</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475675</th>\n",
       "      <td>he did not</td>\n",
       "      <td>223</td>\n",
       "      <td>197</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398770</th>\n",
       "      <td>out of the</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128464</th>\n",
       "      <td>he could not</td>\n",
       "      <td>129</td>\n",
       "      <td>198</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163230</th>\n",
       "      <td>that he was</td>\n",
       "      <td>155</td>\n",
       "      <td>121</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36568</th>\n",
       "      <td>one of the</td>\n",
       "      <td>187</td>\n",
       "      <td>81</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441191</th>\n",
       "      <td>that he had</td>\n",
       "      <td>102</td>\n",
       "      <td>136</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72002</th>\n",
       "      <td>that it was</td>\n",
       "      <td>125</td>\n",
       "      <td>107</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606815</th>\n",
       "      <td>i can t</td>\n",
       "      <td>80</td>\n",
       "      <td>142</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495777</th>\n",
       "      <td>as soon as</td>\n",
       "      <td>146</td>\n",
       "      <td>61</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11691</th>\n",
       "      <td>he had been</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198415</th>\n",
       "      <td>she did not</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433959</th>\n",
       "      <td>did not know</td>\n",
       "      <td>113</td>\n",
       "      <td>80</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59401</th>\n",
       "      <td>up to the</td>\n",
       "      <td>129</td>\n",
       "      <td>59</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296767</th>\n",
       "      <td>in spite of</td>\n",
       "      <td>68</td>\n",
       "      <td>116</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208417</th>\n",
       "      <td>the drawing room</td>\n",
       "      <td>115</td>\n",
       "      <td>64</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>which he had</td>\n",
       "      <td>114</td>\n",
       "      <td>61</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362047</th>\n",
       "      <td>don t know</td>\n",
       "      <td>71</td>\n",
       "      <td>96</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114535</th>\n",
       "      <td>it seemed to</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268007</th>\n",
       "      <td>she could not</td>\n",
       "      <td>66</td>\n",
       "      <td>101</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  N-gram  War and Peace Count  Anna Karenina Count  Total\n",
       "165572           i don t                  203                  254    457\n",
       "475675        he did not                  223                  197    420\n",
       "398770        out of the                  178                  177    355\n",
       "128464      he could not                  129                  198    327\n",
       "163230       that he was                  155                  121    276\n",
       "36568         one of the                  187                   81    268\n",
       "441191       that he had                  102                  136    238\n",
       "72002        that it was                  125                  107    232\n",
       "606815           i can t                   80                  142    222\n",
       "495777        as soon as                  146                   61    207\n",
       "11691        he had been                  102                  103    205\n",
       "198415       she did not                   99                   95    194\n",
       "433959      did not know                  113                   80    193\n",
       "59401          up to the                  129                   59    188\n",
       "296767       in spite of                   68                  116    184\n",
       "208417  the drawing room                  115                   64    179\n",
       "153161      which he had                  114                   61    175\n",
       "362047        don t know                   71                   96    167\n",
       "114535      it seemed to                   96                   71    167\n",
       "268007     she could not                   66                  101    167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Merge bigrams comparison\n",
    "def merge_comparison(counter1, counter2, label1, label2, n=20):\n",
    "    all_ngrams = set(counter1) | set(counter2)\n",
    "    data = []\n",
    "    for ng in all_ngrams:\n",
    "        data.append({\n",
    "            'N-gram': ' '.join(ng),\n",
    "            f'{label1} Count': counter1.get(ng, 0),\n",
    "            f'{label2} Count': counter2.get(ng, 0)\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Total'] = df[f'{label1} Count'] + df[f'{label2} Count']\n",
    "    df = df.sort_values(by='Total', ascending=False).head(n)\n",
    "    return df\n",
    "\n",
    "print(\"### Merged Comparison (Bigrams)\")\n",
    "display(merge_comparison(counter_bi_war, counter_bi_anna, \"War and Peace\", \"Anna Karenina\"))\n",
    "\n",
    "print(\"### Merged Comparison (Trigrams)\")\n",
    "display(merge_comparison(counter_tri_war, counter_tri_anna, \"War and Peace\", \"Anna Karenina\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "193bc2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Separate Comparison (Bigrams)\n",
      "\n",
      "Top 10 shared bigrams:\n",
      "of the ‚Äî Total: 6017\n",
      "in the ‚Äî Total: 3970\n",
      "to the ‚Äî Total: 3336\n",
      "at the ‚Äî Total: 2232\n",
      "he had ‚Äî Total: 2214\n",
      "and the ‚Äî Total: 2211\n",
      "on the ‚Äî Total: 1989\n",
      "he was ‚Äî Total: 1837\n",
      "did not ‚Äî Total: 1691\n",
      "it was ‚Äî Total: 1554\n",
      "\n",
      "### Separate Comparison (Trigrams)\n",
      "i don t ‚Äî Total: 457\n",
      "he did not ‚Äî Total: 420\n",
      "out of the ‚Äî Total: 355\n",
      "he could not ‚Äî Total: 327\n",
      "that he was ‚Äî Total: 276\n",
      "one of the ‚Äî Total: 268\n",
      "that he had ‚Äî Total: 238\n",
      "that it was ‚Äî Total: 232\n",
      "i can t ‚Äî Total: 222\n",
      "as soon as ‚Äî Total: 207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display both separately again for clarity\n",
    "print(\"### Separate Comparison (Bigrams)\")\n",
    "print(\"\\nTop 10 shared bigrams:\")\n",
    "shared_bi = set(counter_bi_war) & set(counter_bi_anna)\n",
    "shared_bi_counts = [(ng, counter_bi_war[ng] + counter_bi_anna[ng]) for ng in shared_bi]\n",
    "shared_bi_sorted = sorted(shared_bi_counts, key=lambda x: x[1], reverse=True)[:10]\n",
    "for ng, count in shared_bi_sorted:\n",
    "    print(f\"{' '.join(ng)} ‚Äî Total: {count}\")\n",
    "\n",
    "print(\"\\n### Separate Comparison (Trigrams)\")\n",
    "shared_tri = set(counter_tri_war) & set(counter_tri_anna)\n",
    "shared_tri_counts = [(ng, counter_tri_war[ng] + counter_tri_anna[ng]) for ng in shared_tri]\n",
    "shared_tri_sorted = sorted(shared_tri_counts, key=lambda x: x[1], reverse=True)[:10]\n",
    "for ng, count in shared_tri_sorted:\n",
    "    print(f\"{' '.join(ng)} ‚Äî Total: {count}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953cd30b",
   "metadata": {},
   "source": [
    "\n",
    "### üìä Summary of Comparison\n",
    "Both books share many common language patterns typical of 19th-century literature.  \n",
    "* Common bigrams like **'of the'**, **'in the'**, or **'to the'** appear frequently in both.  \n",
    "* Unique n-grams often reflect thematic differences ‚Äî *War and Peace* includes more military or political terms, while *Anna Karenina* contains more social and emotional expressions.  \n",
    "You can analyze further by filtering stopwords or increasing the `n` value for deeper contextual insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c748f7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n-gram plots for Anna Karenina -> outputs\\Anna_Karenina_bi_tri_ngrams.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E088] Text of length 1982314 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m     anna_png \u001b[38;5;241m=\u001b[39m OUTDIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnna_Karenina_bi_tri_ngrams.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating n-gram plots for Anna Karenina -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manna_png\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mplot_bigrams_trigrams_for_book\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnna Karenina\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manna_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavepath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manna_png\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved n-gram visualization PNGs if savepath provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 16\u001b[0m, in \u001b[0;36mplot_bigrams_trigrams_for_book\u001b[1;34m(book_title, text, top_k, savepath)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_bigrams_trigrams_for_book\u001b[39m(book_title: \u001b[38;5;28mstr\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, top_k: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, savepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 16\u001b[0m     bigrams \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_ngrams_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     trigrams \u001b[38;5;241m=\u001b[39m get_top_ngrams_from_text(text, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, top_k\u001b[38;5;241m=\u001b[39mtop_k)\n\u001b[0;32m     19\u001b[0m     bigram_labels, bigram_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbigrams) \u001b[38;5;28;01mif\u001b[39;00m bigrams \u001b[38;5;28;01melse\u001b[39;00m ([], [])\n",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m, in \u001b[0;36mget_top_ngrams_from_text\u001b[1;34m(text, n, top_k)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_top_ngrams_from_text\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, n: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, top_k: \u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Tokenize and extract alphabetic tokens\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_alpha]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m<\u001b[39m n:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\language.py:1030\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1011\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1015\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1030\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1032\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\language.py:1121\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[1;34m(self, doc_like)\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m doc_like\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc_like\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\spacy\\language.py:1110\u001b[0m, in \u001b[0;36mLanguage.make_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Turn a text into a Doc object.\u001b[39;00m\n\u001b[0;32m   1105\u001b[0m \n\u001b[0;32m   1106\u001b[0m \u001b[38;5;124;03mtext (str): The text to process.\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03mRETURNS (Doc): The processed doc.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1111\u001b[0m         Errors\u001b[38;5;241m.\u001b[39mE088\u001b[38;5;241m.\u001b[39mformat(length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(text), max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length)\n\u001b[0;32m   1112\u001b[0m     )\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text)\n",
      "\u001b[1;31mValueError\u001b[0m: [E088] Text of length 1982314 exceeds maximum of 1000000. The parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def get_top_ngrams_from_text(text: str, n: int=2, top_k: int=20):\n",
    "    # Tokenize and extract alphabetic tokens\n",
    "    doc = nlp(text)\n",
    "    tokens = [t.text.lower() for t in doc if t.is_alpha]\n",
    "    if len(tokens) < n:\n",
    "        return []\n",
    "    ngrams = (\" \".join(tokens[i:i+n]) for i in range(len(tokens)-n+1))\n",
    "    counts = Counter(ngrams)\n",
    "    return counts.most_common(top_k)\n",
    "\n",
    "\n",
    "def plot_bigrams_trigrams_for_book(book_title: str, text: str, top_k: int=15, savepath=None):\n",
    "    bigrams = get_top_ngrams_from_text(text, n=2, top_k=top_k)\n",
    "    trigrams = get_top_ngrams_from_text(text, n=3, top_k=top_k)\n",
    "\n",
    "    bigram_labels, bigram_vals = zip(*bigrams) if bigrams else ([], [])\n",
    "    trigram_labels, trigram_vals = zip(*trigrams) if trigrams else ([], [])\n",
    "\n",
    "    bigram_labels = list(bigram_labels)[::-1]\n",
    "    bigram_vals = list(bigram_vals)[::-1]\n",
    "    trigram_labels = list(trigram_labels)[::-1]\n",
    "    trigram_vals = list(trigram_vals)[::-1]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10), constrained_layout=True)\n",
    "\n",
    "    # Trigrams\n",
    "    ax = axes[0]\n",
    "    y_pos = range(len(trigram_labels))\n",
    "    ax.barh(y_pos, trigram_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(trigram_labels, fontsize=10)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "    ax.set_title(f\"{book_title} ‚Äî Top {top_k} Trigrams\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Bigrams\n",
    "    ax = axes[1]\n",
    "    y_pos = range(len(bigram_labels))\n",
    "    ax.barh(y_pos, bigram_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(bigram_labels, fontsize=10)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "    ax.set_title(f\"{book_title} ‚Äî Top {top_k} Bigrams\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return savepath, fig\n",
    "\n",
    "# Run for both books (assuming file_war, file_anna, read_text, strip_gutenberg_headers, and OUTDIR defined earlier)\n",
    "if 'war_file' in globals():\n",
    "    war_text = strip_gutenberg_headers(read_text(file_war))\n",
    "    war_png = OUTDIR / \"War_and_Peace_bi_tri_ngrams.png\"\n",
    "    print(f\"Creating n-gram plots for War and Peace -> {war_png}\")\n",
    "    plot_bigrams_trigrams_for_book(\"War and Peace\", war_text, top_k=15, savepath=str(war_png))\n",
    "\n",
    "if 'file_anna' in globals():\n",
    "    anna_text = strip_gutenberg_headers(read_text(file_anna))\n",
    "    anna_png = OUTDIR / \"Anna_Karenina_bi_tri_ngrams.png\"\n",
    "    print(f\"Creating n-gram plots for Anna Karenina -> {anna_png}\")\n",
    "    plot_bigrams_trigrams_for_book(\"Anna Karenina\", anna_text, top_k=15, savepath=str(anna_png))\n",
    "\n",
    "print(\"Saved n-gram visualization PNGs if savepath provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca8c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spaCy model...\n",
      "‚ö†Ô∏è War_and_Peace.txt not found in current directory; please add it.\n",
      "‚ö†Ô∏è Anna_Karenina.txt not found in current directory; please add it.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Fully self-contained chunked n-gram analysis + plotting\n",
    "# Works for War and Peace and Anna Karenina\n",
    "# ==========================================\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- SETUP ----------\n",
    "print(\"Loading spaCy model...\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "OUTDIR = Path(\"outputs\")\n",
    "OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "def read_text(path):\n",
    "    \"\"\"Read UTF-8 text from file.\"\"\"\n",
    "    return Path(path).read_text(encoding='utf-8', errors='ignore')\n",
    "\n",
    "def strip_gutenberg_headers(text):\n",
    "    \"\"\"Remove Project Gutenberg headers/footers.\"\"\"\n",
    "    text = re.sub(r\"\\*\\*\\* START OF.*?\\*\\*\\*\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"\\*\\*\\* END OF.*?\\*\\*\\*\", \"\", text, flags=re.DOTALL)\n",
    "    return text.strip()\n",
    "\n",
    "def get_paragraph_chunks(text: str):\n",
    "    \"\"\"Split into paragraph-like chunks (based on blank lines), falling back to fixed-size chunks.\"\"\"\n",
    "    text = text.replace('\\r\\n', '\\n')\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    max_paragraph_length = 20000\n",
    "    chunks = []\n",
    "    for p in paragraphs:\n",
    "        if len(p) <= max_paragraph_length:\n",
    "            chunks.append(p)\n",
    "        else:\n",
    "            start = 0\n",
    "            L = len(p)\n",
    "            while start < L:\n",
    "                end = min(start + max_paragraph_length, L)\n",
    "                if end < L:\n",
    "                    nxt = p.rfind(' ', start, end)\n",
    "                    if nxt > start:\n",
    "                        end = nxt\n",
    "                chunks.append(p[start:end].strip())\n",
    "                start = end\n",
    "    return chunks\n",
    "\n",
    "def get_top_ngrams_from_text_chunked(text: str, n: int=2, top_k: int=20):\n",
    "    \"\"\"Efficiently compute top n-grams from a large text by processing in chunks.\"\"\"\n",
    "    counts = Counter()\n",
    "    chunks = [c for c in get_paragraph_chunks(text) if c]\n",
    "    if not chunks:\n",
    "        return []\n",
    "    for doc in nlp.pipe(chunks, batch_size=50):\n",
    "        tokens = [t.text.lower() for t in doc if t.is_alpha]\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            gram = \" \".join(tokens[i:i+n])\n",
    "            counts[gram] += 1\n",
    "    return counts.most_common(top_k)\n",
    "\n",
    "def plot_bigrams_trigrams_for_book_chunked(book_title: str, text: str, top_k: int=15, savepath=None):\n",
    "    bigrams = get_top_ngrams_from_text_chunked(text, n=2, top_k=top_k)\n",
    "    trigrams = get_top_ngrams_from_text_chunked(text, n=3, top_k=top_k)\n",
    "\n",
    "    bigram_labels, bigram_vals = zip(*bigrams) if bigrams else ([], [])\n",
    "    trigram_labels, trigram_vals = zip(*trigrams) if trigrams else ([], [])\n",
    "\n",
    "    bigram_labels = list(bigram_labels)[::-1]\n",
    "    bigram_vals = list(bigram_vals)[::-1]\n",
    "    trigram_labels = list(trigram_labels)[::-1]\n",
    "    trigram_vals = list(trigram_vals)[::-1]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10), constrained_layout=True)\n",
    "\n",
    "    # Trigrams\n",
    "    ax = axes[0]\n",
    "    y_pos = range(len(trigram_labels))\n",
    "    ax.barh(y_pos, trigram_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(trigram_labels, fontsize=9)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "    ax.set_title(f\"{book_title} ‚Äî Top {top_k} Trigrams\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Bigrams\n",
    "    ax = axes[1]\n",
    "    y_pos = range(len(bigram_labels))\n",
    "    ax.barh(y_pos, bigram_vals)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(bigram_labels, fontsize=9)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "    ax.set_title(f\"{book_title} ‚Äî Top {top_k} Bigrams\")\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    if savepath:\n",
    "        Path(savepath).parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(savepath, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Saved plot to: {savepath}\")\n",
    "    plt.show()\n",
    "    return savepath, fig\n",
    "\n",
    "# ---------- MAIN EXECUTION ----------\n",
    "# Point these to your actual text files\n",
    "file_war = Path(\"War_and_Peace.txt\")\n",
    "anna_file = Path(\"Anna_Karenina.txt\")\n",
    "\n",
    "if file_war.exists():\n",
    "    print(\"Processing War and Peace (chunked)...\")\n",
    "    war_text = strip_gutenberg_headers(read_text(file_war))\n",
    "    war_png = OUTDIR / \"War_and_Peace_bi_tri_ngrams_chunked.png\"\n",
    "    plot_bigrams_trigrams_for_book_chunked(\"War and Peace\", war_text, top_k=15, savepath=str(war_png))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è War_and_Peace.txt not found in current directory; please add it.\")\n",
    "\n",
    "if anna_file.exists():\n",
    "    print(\"Processing Anna Karenina (chunked)...\")\n",
    "    anna_text = strip_gutenberg_headers(read_text(anna_file))\n",
    "    anna_png = OUTDIR / \"Anna_Karenina_bi_tri_ngrams_chunked.png\"\n",
    "    plot_bigrams_trigrams_for_book_chunked(\"Anna Karenina\", anna_text, top_k=15, savepath=str(anna_png))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Anna_Karenina.txt not found in current directory; please add it.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3783b",
   "metadata": {},
   "source": [
    "-\"War and Peace\" feels like author's voice the most since it includes more characters such as commander in chief, the old prince, the drawing room, prince andrew (andrei)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe860379",
   "metadata": {},
   "source": [
    "-Most frequent items in Anna karenina are mostly common phrases people use nowadays, so there are couple items that is part of author's work like \"said stepan arkadyevitch\" andd \"alexeey alexandrovitch. As for War and peace - there are more frequent items that are characters and interesting words like \"the drawing room\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
