#Jakhongir Erkinov
# Colab-ready single cell. Uses Colab's built-in numpy/pandas/matplotlib; installs only nltk + networkx.

!pip -q install nltk networkx

import os, re
from itertools import combinations
from collections import defaultdict
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
import nltk


try:
    from google.colab import files
    COLAB = True
except:
    COLAB = False

# Sentiment (VADER)
nltk.download('vader_lexicon', quiet=True)
from nltk.sentiment import SentimentIntensityAnalyzer
SIA = SentimentIntensityAnalyzer()

# ---- Filenames (edit if needed) ----
BOOK_A = "The Project Gutenberg eBook of Anna Karenina, by Leo Tolstoy.txt"
BOOK_B = "The_Project_Gutenberg_eBook_of_War_and_Peace,_by_Leo_Tolstoy_1.txt"

# ---- Params ----
MIN_PAIR_FREQ  = 3      # drop weak edges (sentences co-occurred)
TOP_K_TABLE    = 12     # how many rows to show in pos/neg tables
TOP_M_EDGES    = 25     # strongest M edges to draw (None = all)
SEED           = 42     # layout seed

# ================== CHARACTER WHITELISTS (aliases; all lowercase) ==================

AK_ALIASES = {
    "anna karenina": ["anna karenina","anna","anna arkadyevna"],
    "vronsky": ["vronsky","alexei vronsky","alexey vronsky","count vronsky","alexeï vronsky"],
    "karenin": ["karenin","alexei alexandrovich","alexey alexandrovitch","alexeï alexandrovitch"],
    "levin": ["levin","konstantin levin","kostya","konstantin dmitrich","konstantin dmitrievich"],
    "kitty": ["kitty","katerina shcherbatskaya","ekaterina","katerina alexandrovna"],
    "dolly": ["dolly","darya alexandrovna","daria alexandrovna"],
    "stiva": ["stiva","stepan arkadyevich","stepan arkadyevitch","oblonsky","stepan"],
    "serguei": ["seryozha","sergei","serguei","sergey","sergei alexeyevich"],
    "sergey ivanovich": ["sergey ivanovich","sergei ivanovich","koznishev","koznyshev","sergey ivanovitch"],
    "varenka": ["varenka","varen'ka"],
    "betsy": ["betsy","princess betsy","betsy tverskaya","princess tverskaya"],
    "lydia": ["lydia","lydia ivanovna"],
    "nikolai levin": ["nikolai levin","nikolai","nikolenka"],
    "agafya": ["agafya","agafya mikhailovna"],
}

WAP_ALIASES = {
    "pierre bezukhov": ["pierre","bezukhov","pierre bezukhov"],
    "prince andrei bolkonsky": ["prince andrei","andrei","andrew","bolkonsky","andrei bolkonsky"],
    "natasha rostova": ["natasha","natalia","natalie","rostova","natasha rostov"],
    "nikolai rostov": ["nikolai","nicholas","nikolenka","rostov","nikolai rostov"],
    "sonya": ["sonya","sophie"],
    "princess marya": ["marya","princess marya","maria","mary","marya bolkonskaya"],
    "anatole kuragin": ["anatole","kuragin"],
    "helene": ["helene","elena","hélène","helene kuragin"],
    "dolokhov": ["dolokhov","fedor dolokhov","fyodor dolokhov"],
    "denisov": ["denisov","vasili denisov","denisov the hussar"],
    "kutuzov": ["kutuzov","koutouzov","mikhail kutuzov","kutusov"],
    "napoleon": ["napoleon","bonaparte","napoléon"],
    "old prince bolkonsky": ["old prince","old prince bolkonsky","prince nikolai andreyevich"],
    "vera rostova": ["vera","vera rostova"],
    "petya rostov": ["petya","petr","petya rostov"],
    "berg": ["berg"],
    "boris drubetskoy": ["boris","boris drubetskoy","drubetskoy"],
    "anna pavlovna": ["anna pavlovna","anna p.","annette schérer","schérer","scherer"],  # optional
}


DISPLAY_NAME = {
    "old prince bolkonsky": "Old Prince Bolkonsky (Nikolai)",
    "prince andrei bolkonsky": "Prince Andrei Bolkonsky (son)",
    "serguei": "Seryozha (Anna’s son)",
    "sergey ivanovich": "Sergey Ivanovich (Levin’s brother)"
}

# ================== UTILITIES ==================
def ensure_text(path, label):
    if os.path.exists(path):
        print(f"Found {label}: {path}")
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            return f.read()
    if COLAB:
        print(f"{label} not found. Upload TXT for {label} …")
        up = files.upload()
        if not up:
            raise RuntimeError(f"No upload for {label}.")
        fname = list(up.keys())[0]
        print(f"Loaded: {fname}")
        return up[fname].decode("utf-8", errors="ignore")
    raise FileNotFoundError(path)

def split_sentences(text):
    text = re.sub(r"\s+", " ", text).strip()
    return [s.strip() for s in re.split(r"(?<=[.!?])\s+", text) if s.strip()]

def compile_alias_patterns(alias_dict):
    patt = {}
    for canon, aliases in alias_dict.items():
        al_sorted = sorted(set(a.lower() for a in aliases), key=len, reverse=True)
        al_regexes = [r"\b" + re.escape(a).replace("\\ ", r"\s+") + r"\b" for a in al_sorted]
        patt[canon] = re.compile("|".join(al_regexes), flags=re.IGNORECASE)
    return patt

def find_mentions_in_sentence(sent, patt_map):
    found = set()
    low = sent.lower()
    for canon, rgx in patt_map.items():
        if rgx.search(low):
            found.add(canon)
    return found

def build_edges(sentences, patt_map):
    from nltk.sentiment import SentimentIntensityAnalyzer
    SIA_local = SentimentIntensityAnalyzer()  # ensure available in worker
    edges = defaultdict(lambda: {"w":0, "comp_sum":0.0, "ctx":0})
    for s in sentences:
        chars = sorted(find_mentions_in_sentence(s, patt_map))
        if len(chars) < 2:
            continue
        comp = SIA_local.polarity_scores(s)["compound"]
        for a,b in combinations(chars, 2):
            k = (a,b)
            edges[k]["w"] += 1
            edges[k]["comp_sum"] += comp
            edges[k]["ctx"] += 1
    rows = []
    for (a,b), d in edges.items():
        if d["w"] >= MIN_PAIR_FREQ:
            rows.append({
                "source": a, "target": b,
                "weight": d["w"],
                "mean_sentiment": round(d["comp_sum"]/max(1,d["ctx"]), 4)
            })
    return pd.DataFrame(rows).sort_values(["weight","mean_sentiment"], ascending=[False, False])

def top_pairs(df, k=TOP_K_TABLE):
    if df.empty: return (pd.DataFrame(), pd.DataFrame())
    pos = df.sort_values("mean_sentiment", ascending=False).head(k)
    neg = df.sort_values("mean_sentiment", ascending=True ).head(k)
    return pos[["source","target","weight","mean_sentiment"]], neg[["source","target","weight","mean_sentiment"]]

def titlecase(name: str) -> str:
    return " ".join(w.capitalize() for w in name.split())

def apply_display_names(df):
    # Capitalize first, then apply friendly replacements if keys match
    df["source"] = df["source"].map(titlecase)
    df["target"] = df["target"].map(titlecase)
    # map back to lowercase keys for replacement lookup
    df["source"] = df["source"].apply(lambda s: DISPLAY_NAME.get(s.lower(), s))
    df["target"] = df["target"].apply(lambda s: DISPLAY_NAME.get(s.lower(), s))
    return df

def graph_from_edges(df):
    G = nx.Graph()
    for _, r in df.iterrows():
        G.add_edge(r["source"], r["target"],
                   weight=float(r["weight"]),
                   sentiment=float(r["mean_sentiment"]))
    return G

def build_shared_layout(dfA, dfB, seed=SEED):
    G_all = nx.Graph()
    for df in (dfA, dfB):
        for _, r in df.iterrows():
            G_all.add_edge(r["source"], r["target"])
    return nx.spring_layout(G_all, seed=seed, k=0.7)

def plot_network(df, title, pos=None, out_png=None, seed=SEED, top_m=TOP_M_EDGES):
    if df.empty:
        print(f"[{title}] No edges to plot."); return
    if isinstance(top_m, int):
        df = df.sort_values("weight", ascending=False).head(top_m)
    G = graph_from_edges(df)
    if pos is None:
        pos = nx.spring_layout(G, k=0.7, seed=seed)
    deg = dict(G.degree())
    node_sizes = [240 + 60*deg[n] for n in G.nodes()]
    edge_w = [1.0 + 1.2*np.log1p(w) for w in nx.get_edge_attributes(G, "weight").values()]
    sentiments = [G[u][v]["sentiment"] for u,v in G.edges()]
    mn, mx = min(sentiments), max(sentiments); rng = (mx-mn) if mx!=mn else 1.0
    normed = [(s-mn)/rng for s in sentiments]
    fig, ax = plt.subplots(figsize=(10,8))
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, ax=ax)
    nx.draw_networkx_edges(G, pos, width=edge_w, edge_color=normed,
                           edge_cmap=plt.cm.coolwarm, alpha=0.8, ax=ax)
    nx.draw_networkx_labels(G, pos, font_size=10, ax=ax)
    sm = plt.cm.ScalarMappable(cmap=plt.cm.coolwarm); sm.set_array(sentiments)
    fig.colorbar(sm, ax=ax, label="edge sentiment (relative)")
    ax.set_title(title); ax.set_axis_off()
    if out_png: fig.savefig(out_png, dpi=200, bbox_inches="tight")
    plt.show()

def polarity_share(df):
    if df.empty: return (0.0, 0.0)
    pos_share = float((df["mean_sentiment"] > 0.05).mean())
    neg_share = float((df["mean_sentiment"] < -0.05).mean())
    return round(pos_share,3), round(neg_share,3)

def print_cast_legend(alias_map, title):
    print(f"\n{title} — Cast Legend (canonical → example aliases)")
    for canon, aliases in sorted(alias_map.items()):
        shown = ", ".join(sorted(set(aliases))[:3])
        print(f"  - {titlecase(canon)} → {shown}")

# ================== Load, Run, Plot ==================
textA = (open(BOOK_A, "r", encoding="utf-8", errors="ignore").read()
         if os.path.exists(BOOK_A) else ensure_text(BOOK_A, "Book A"))
textB = (open(BOOK_B, "r", encoding="utf-8", errors="ignore").read()
         if os.path.exists(BOOK_B) else ensure_text(BOOK_B, "Book B"))

sentsA = split_sentences(textA); print(f"AnnaKarenina: {len(sentsA):,} sentences")
sentsB = split_sentences(textB); print(f"WarAndPeace: {len(sentsB):,} sentences")

pattA = compile_alias_patterns(AK_ALIASES)
pattB = compile_alias_patterns(WAP_ALIASES)

edgesA = build_edges(sentsA, pattA)
edgesB = build_edges(sentsB, pattB)

# Nicer labels (no FutureWarning) + friendly replacements
edgesA = apply_display_names(edgesA)
edgesB = apply_display_names(edgesB)

edgesA.to_csv("edges_AnnaKarenina.csv", index=False)
edgesB.to_csv("edges_WarAndPeace.csv", index=False)
print(f"Saved edges_AnnaKarenina.csv ({len(edgesA)} edges)")
print(f"Saved edges_WarAndPeace.csv ({len(edgesB)} edges)")

# Top pairs tables
posA = edgesA.sort_values("mean_sentiment", ascending=False).head(TOP_K_TABLE)[["source","target","weight","mean_sentiment"]]
negA = edgesA.sort_values("mean_sentiment", ascending=True ).head(TOP_K_TABLE)[["source","target","weight","mean_sentiment"]]
posB = edgesB.sort_values("mean_sentiment", ascending=False).head(TOP_K_TABLE)[["source","target","weight","mean_sentiment"]]
negB = edgesB.sort_values("mean_sentiment", ascending=True ).head(TOP_K_TABLE)[["source","target","weight","mean_sentiment"]]

if not posA.empty: print("\nAnna Karenina — Top positive pairs:"); display(posA)
if not negA.empty: print("\nAnna Karenina — Top negative pairs:"); display(negA)
if not posB.empty: print("\nWar and Peace — Top positive pairs:"); display(posB)
if not negB.empty: print("\nWar and Peace — Top negative pairs:"); display(negB)

# Shared layout for side-by-side comparability
shared_pos = build_shared_layout(edgesA, edgesB, seed=SEED)

plot_network(edgesA, "AnnaKarenina — Character Network", pos=shared_pos,
             top_m=TOP_M_EDGES, seed=SEED, out_png="network_AnnaKarenina.png")
plot_network(edgesB, "WarAndPeace — Character Network", pos=shared_pos,
             top_m=TOP_M_EDGES, seed=SEED, out_png="network_WarAndPeace.png")

pa, na = polarity_share(edgesA)
pb, nb = polarity_share(edgesB)
print("\n=== Comparative summary ===")
print(f"Anna Karenina: edges={len(edgesA)}, positive_share={pa}, negative_share={na}")
print(f"War and Peace: edges={len(edgesB)}, positive_share={pb}, negative_share={nb}")

# Optional: print cast legends so readers know who is who
print_cast_legend(AK_ALIASES, "Anna Karenina")
print_cast_legend(WAP_ALIASES, "War and Peace")
